{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moral-voice",
   "metadata": {},
   "source": [
    "### 프로젝트 평가 문항\n",
    "1) 3가지 데이터셋 구성 합리적으로 진행 됐나?  \n",
    ": feature, label 선정 위한 데이터 분석과정이 체계적으로 전개됨  \n",
    "\n",
    "2) 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용했는가?  \n",
    ": 모델 학습 및 테스트가 정상적으로 수행  \n",
    "\n",
    "3) 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택됐나?  \n",
    ": 평가지표 선택 및 이유 설명이 타당함\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2-11. 프로젝트 (1) digits\n",
    "\n",
    "Samples total= 데이터수는 1797개  \n",
    "class= 라벨 =10개  \n",
    "Dimensionality = 차원 = 64픽셀 =feature  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-enclosure",
   "metadata": {},
   "source": [
    "### 1. 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-species",
   "metadata": {},
   "source": [
    "### 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_digits 은 위에서 이미했고\n",
    "digits = load_digits()\n",
    "\n",
    "#Feature Data 지정하기\n",
    "digits_data = digits.data\n",
    "#print(digists_data.shape) -> (1797, 64) : 1764개 샘플/데이터, 64개 특징\n",
    "\n",
    "#Label Data 지정하기\n",
    "digits_target = digits.target\n",
    "#print(digists_target.shape) -> (1797,) : 열벡터 타겟 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-functionality",
   "metadata": {},
   "source": [
    "### 3. 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finite-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "asian-treasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surgical-north",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parental-distributor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "#데이터셋 설명 \n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "complicated-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    183\n",
      "1    182\n",
      "5    182\n",
      "4    181\n",
      "6    181\n",
      "9    180\n",
      "7    179\n",
      "0    178\n",
      "2    177\n",
      "8    174\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#데이터 분류 어떻게 되어있나 확인\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.Series(digits.target).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-transsexual",
   "metadata": {},
   "source": [
    "### 4. 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "northern-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-access",
   "metadata": {},
   "source": [
    "### 5. 다양한 모델로 학습 및 평가\n",
    "\n",
    "#### 1) Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "brutal-cotton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "#모델생성\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "#모델학습\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#예측\n",
    "dt_pred = decision_tree.predict(X_test)\n",
    "\n",
    "#모델평가 - 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt_pred)\n",
    "print(accuracy)\n",
    "\n",
    "#모델평가 - 오차행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrix(y_test, dt_pred)\n",
    "dt_c_m = classification_report(y_test, dt_pred)\n",
    "#print(classification_report(y_test, dt_pred))   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-tobacco",
   "metadata": {},
   "source": [
    "#### 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "metallic-cleveland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#모델생성\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "#모델학습\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#예측\n",
    "rf_pred = random_forest.predict(X_test)\n",
    "\n",
    "#모델평가 - 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(accuracy)\n",
    "\n",
    "#모델평가 - 오차행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrix(y_test, rf_pred)\n",
    "rf_c_m = classification_report(y_test, rf_pred)\n",
    "\n",
    "#print(classification_report(y_test, rf_pred))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-reviewer",
   "metadata": {},
   "source": [
    "#### 3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "leading-breakdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "#모델생성\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "#모델학습\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#예측\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "#모델평가 - 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(accuracy)\n",
    "\n",
    "#모델평가 - 오차행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrix(y_test, svm_pred)\n",
    "svm_c_m = classification_report(y_test, svm_pred)\n",
    "\n",
    "#print(classification_report(y_test, svm_pred))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-respondent",
   "metadata": {},
   "source": [
    "#### 4)SGDC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "transsexual-consumption",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194444444444444\n"
     ]
    }
   ],
   "source": [
    "#모델생성\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "#모델학습\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "#예측\n",
    "SGDC_pred = sgd_model.predict(X_test)\n",
    "\n",
    "#모델평가 - 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test,SGDC_pred)\n",
    "print(accuracy)\n",
    "\n",
    "#모델평가 - 오차행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrix(y_test, SGDC_pred)\n",
    "SGDC_c_m = classification_report(y_test, SGDC_pred)\n",
    "\n",
    "#print(classification_report(y_test, SGDC_pred))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-calculator",
   "metadata": {},
   "source": [
    "#### 5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "complete-farmer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9527777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#모델생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "#모델학습\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "#예측\n",
    "lr_pred = logistic_model.predict(X_test)\n",
    "\n",
    "#모델평가 - 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(accuracy)\n",
    "\n",
    "#모델평가 - 오차행렬\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "confusion_matrix(y_test, lr_pred)\n",
    "lr_c_m = classification_report(y_test,lr_pred)\n",
    "\n",
    "#print(classification_report(y_test,lr_pred))   \n",
    "\n",
    "#max_iter'까지 학습했으나 아직 정답에 수렴하지 못한 상태<- 라고 경고문이 뜸\n",
    "#max_iter=500으로 늘려야 할 것 같습니다.  적절값 테스트는 반복 변경해 가면서 찾아야 할 것\n",
    "#max_iter이 여기서 무엇인가 -> 이터레이터...!\n",
    "#옴.. 근데 어떤 값을 바꿔야될지 모르니까, 스터디에 질문하쟝..ㅠ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-nightlife",
   "metadata": {},
   "source": [
    "### 6. 모델 선택 및 평가지표\n",
    "선택 모델 : SVM 모델  \n",
    "-> 모든 평가지표의 정확도가 가장 높게 나왔음 \n",
    "\n",
    "0~9까지 라벨중에 중경의 의미를 따질 수 없다고 판단  \n",
    "때문에 recall과 precision 중에  \n",
    "더 중요하게 평가해야하는 지표를 판단 할 수 없다고 생각  \n",
    "와중에 svm 모델이 모든 평가지표 가장 높게 나왔기 때문에 svm 모델 선택\n",
    "데이터 뷴류도 고른편이니 해당 평가지표를 신뢰할 수도 있을 것 같음  \n",
    "\n",
    "* macro avg :  \n",
    "평균들의 평균 개념    \n",
    "전체 성능을 평가하기 위해 모든 클래스에 동일한 가중치를 부여  \n",
    "precision의 값들의 평균  \n",
    "recall 값들의 평균 들의 값\n",
    "<br>\n",
    "\n",
    "* weighted avg  \n",
    "실제 인스턴스 수에 따라 각 클래스의 점수에 가중치를 부여하여 계산하는 방법  \n",
    "클래스 불균형을 다룰 때 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-campus",
   "metadata": {},
   "source": [
    "#### 1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "least-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.82      0.88      0.85        42\n",
      "           2       0.82      0.80      0.81        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.85      0.92      0.88        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.93      0.93      0.93        28\n",
      "           7       0.93      0.79      0.85        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.79      0.84      0.82        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.87      0.86       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dt_c_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-toolbox",
   "metadata": {},
   "source": [
    "#### 2) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "false-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.92      1.00      0.96        34\n",
      "           4       0.90      1.00      0.95        37\n",
      "           5       0.90      1.00      0.95        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       1.00      0.81      0.90        43\n",
      "           9       1.00      0.91      0.95        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_c_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-withdrawal",
   "metadata": {},
   "source": [
    "#### 3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "honest-finder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(svm_c_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-criterion",
   "metadata": {},
   "source": [
    "#### 4) SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "oriented-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.96      0.64      0.77        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.91      0.93        34\n",
      "           4       0.92      0.97      0.95        37\n",
      "           5       0.85      1.00      0.92        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       1.00      0.91      0.95        33\n",
      "           8       0.73      0.93      0.82        43\n",
      "           9       0.97      0.94      0.95        32\n",
      "\n",
      "    accuracy                           0.92       360\n",
      "   macro avg       0.93      0.92      0.92       360\n",
      "weighted avg       0.93      0.92      0.92       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(SGDC_c_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-rebel",
   "metadata": {},
   "source": [
    "#### 5) logist regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "institutional-click",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lr_c_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
